{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ffca31-3740-4ce7-8957-5f9c8db2118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession #Import para sessão spark\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType #Imports para estrutura e tipos\n",
    "\n",
    "from delta import *\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"py4j\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26601a0d-fcff-408b-aa30-ca3d5ea7675c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/23 14:05:50 WARN Utils: Your hostname, Guichard resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/23 14:05:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/guichard/.cache/pypoetry/virtualenvs/engenharia-de-dados-apache-spark-FSwoO1eP-py3.12/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/guichard/.ivy2/cache\n",
      "The jars for the packages stored in: /home/guichard/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0de7995c-a28c-4f26-8f8c-ccf6701a9bf2;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.0.0 in central\n",
      "\tfound io.delta#delta-storage;3.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 407ms :: artifacts dl 14ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0de7995c-a28c-4f26-8f8c-ccf6701a9bf2\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/11ms)\n",
      "25/04/23 14:06:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/23 14:06:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "#Confiraçã0 da Sessão spark\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.0.0\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d828e48-8c83-40d7-aa4a-e025bd47f8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.255.255.254:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb915c72cc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark # Sessão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c80e08-7761-4e8b-a550-01396748fcb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---+-------+--------------+\n",
      "|ID_CLIENTE|NOME_CLIENTE|UF |STATUS |LIMITE_CREDITO|\n",
      "+----------+------------+---+-------+--------------+\n",
      "|ID001     |CLIENTE_X   |SP |ATIVO  |250000.0      |\n",
      "|ID002     |CLIENTE_Y   |SC |INATIVO|400000.0      |\n",
      "|ID003     |CLIENTE_Z   |DF |ATIVO  |1000000.0     |\n",
      "+----------+------------+---+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Simulação base de clientes\n",
    "data = [\n",
    "    (\"ID001\", \"CLIENTE_X\",\"SP\",\"ATIVO\",   250000.00),\n",
    "    (\"ID002\", \"CLIENTE_Y\",\"SC\",\"INATIVO\", 400000.00),\n",
    "    (\"ID003\", \"CLIENTE_Z\",\"DF\",\"ATIVO\",   1000000.00)\n",
    "]\n",
    "\n",
    "schema = (\n",
    "    StructType([\n",
    "        StructField(\"ID_CLIENTE\",     StringType(),True), #True = Pode ser nulo\n",
    "        StructField(\"NOME_CLIENTE\",   StringType(),True),\n",
    "        StructField(\"UF\",             StringType(),True),\n",
    "        StructField(\"STATUS\",         StringType(),True),\n",
    "        StructField(\"LIMITE_CREDITO\", FloatType(), True)\n",
    "    ])\n",
    ")\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=schema) #Dataframe\n",
    "\n",
    "df.show(truncate=False) #Permite visualizar os dados sem quebrar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ecc19-244f-48fe-b40e-a68ecd8334aa",
   "metadata": {},
   "source": [
    "# Grava Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35a80a6-95cb-4c1f-b08c-26a04b0cfb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/23 14:06:35 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Gera uma delta table a partir do dataframe\n",
    "\n",
    "(\n",
    "    df\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(\"./RAW/CLIENTES\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f142e-a13f-4a48-ba54-240e6b5e469b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Simulação de cenário (NOVOS DADOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714eedff-70f0-4d0c-b720-34d069413e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [\n",
    "    (\"ID001\",\"CLIENTE_X\",\"SP\",\"INATIVO\", 0.00),\n",
    "    (\"ID002\",\"CLIENTE_Y\",\"SC\",\"ATIVO\",   400000.00),\n",
    "    (\"ID004\",\"CLIENTE_Z\",\"DF\",\"ATIVO\",   5000000.00)\n",
    "] # Novo lote da partição do data lake\n",
    "\n",
    "df_new = spark.createDataFrame(data=new_data, schema=schema) # Cria um dataframe com os novo dados\n",
    "\n",
    "df_new.show() # Mostra o dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa9501-6178-433e-8fcd-ee78c0fb27eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# UPSERT / MERGE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaee6d1-cfe1-46de-8e62-9bd317bb020d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### OBS: Não ler delta tables com read parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1607b6da-e8ed-4246-a447-bb110ccdf63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da delta table\n",
    "delta_table= DeltaTable.forPath(spark, \"./RAW/CLIENTES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef9cdb-2c73-4dd2-a51f-0f298615fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_table.toDF().show() #Transforma a leitura em um dataframe e da output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdacb383-2637-41d4-93f3-b1a75c1ac990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE\n",
    "(\n",
    "    delta_table.alias(\"dados_atuais\")\n",
    "    .merge(\n",
    "        df_new.alias(\"novos_dados\"),\n",
    "        \"dados_atuais.ID_CLIENTE = novos_dados.ID_CLIENTE\" # Relacionamento de chaves\n",
    "    )\n",
    "    .whenMatchedUpdateAll()\n",
    "    .whenNotMatchedInsertAll() # All se refere a todos os dados, caso queira especificar, é possível remover o all colocar apenas o desejado.\n",
    "    .execute() # executa\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c678a00-55e5-4a03-a402-0eabf99722cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_table.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99132b-43ba-4e1b-9233-8d3827e76ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete\n",
    "delta_table.delete(\"LIMITE_CREDITO < 400000.0\") #Condição (Não exclui fisicamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc9c41-2924-499e-b276-95de7df7c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_table.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a304b870-3cd9-4462-a308-8e5418d86204",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Operações com delta table (CRUD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e11be2-2d21-4b90-afc5-b8fc31b72b44",
   "metadata": {},
   "source": [
    "# CRIAÇÃO DE TABELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aac37b6-bad9-4891-86ac-a28d7bb521a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "schema_clientes = (\n",
    "    StructType([\n",
    "        StructField(\"id\",     StringType(),False), #True = Pode ser nulo\n",
    "        StructField(\"nome_cliente\",   StringType(),False),\n",
    "        StructField(\"uf\",             StringType(),False),\n",
    "        StructField(\"status\",         StringType(),False),\n",
    "        StructField(\"cidade\",         StringType(),False),\n",
    "        StructField(\"limite_credito\", FloatType(), True)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678ad58b-aab0-4126-82ff-930326faef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/23 13:28:51 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criação da tabela cliente_delta\n",
    "spark.sql(\n",
    "     \"\"\"\n",
    "     CREATE TABLE IF NOT EXISTS default.clientes_delta (\n",
    "         id INT NOT NULL,\n",
    "         nome_cliente STRING NOT NULL,\n",
    "         uf CHAR(2) NOT NULL,\n",
    "         status BOOLEAN NOT NULL,\n",
    "         limite_credito FLOAT NOT NULL\n",
    "     ) USING delta\n",
    "     \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3653f22-f525-4ead-a355-1c5d38ccac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+---+------+--------------+\n",
      "| id|nome_cliente| uf|status|limite_credito|\n",
      "+---+------------+---+------+--------------+\n",
      "+---+------------+---+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Relaiza um select na tabela criada e faz o output\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * from default.clientes_delta\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b69d83-b2c9-470f-ad7c-9ea50a0cc7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------+\n",
      "|namespace|     tableName|isTemporary|\n",
      "+---------+--------------+-----------+\n",
      "|  default|clientes_delta|      false|\n",
      "+---------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3565304c-66a3-42ee-9550-5d995a484168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da delta table para cliente delta\n",
    "cliente = DeltaTable.forPath(spark, \"./spark-warehouse/clientes_delta\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d005e317-e6f8-4f87-b971-2d883a0f4506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+---+------+--------------+\n",
      "| id|nome_cliente| uf|status|limite_credito|\n",
      "+---+------------+---+------+--------------+\n",
      "+---+------------+---+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cliente.toDF().show() # Transforma a leitura em um Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa4720-b554-4f0e-96b7-94bebbf19ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra o histórico\n",
    "cliente.history().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb3ee95-a163-490d-a262-d02ea1f618eb",
   "metadata": {},
   "source": [
    "# INSERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d949959e-6e5e-4b3f-8b22-316373508b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INSERT\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "        INSERT INTO default.clientes_delta VALUES \n",
    "        (1, 'Jean Guichard²', 'RS', false, 10000000.0), \n",
    "        (2, 'Lucas da Rosa', 'SC', true, 1000000.0), \n",
    "        (3, 'Matheus Daminelli', 'SC', true, 4000000.0)   \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af7f16-58a0-4184-ac5c-6558c19d2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "        INSERT INTO default.clientes_delta VALUES    \n",
    "        (4, 'Teste da Silva', 'SP', true, 8000000.0, 'Testenópolis')   \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de8607b9-fe6f-4e05-af27-af6bb2e410ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+---+------+--------------+--------+\n",
      "| id|     nome_cliente| uf|status|limite_credito|  cidade|\n",
      "+---+-----------------+---+------+--------------+--------+\n",
      "|  3|Matheus Daminelli| SC|  true|     4000000.0|Criciúma|\n",
      "|  2|    Lucas da Rosa| SC|  true|     1000000.0| Tubarão|\n",
      "|  1|   Jean Guichard²| RS| false|         1.0E7|  Torres|\n",
      "+---+-----------------+---+------+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * from default.clientes_delta\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14d54ef7-6438-445a-88d9-30e92c2618fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+------------+-----------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation   |operationParameters                                                          |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                           |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+------------+-----------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "|1      |2025-04-22 20:38:03.791|NULL  |NULL    |WRITE       |{mode -> Append, partitionBy -> []}                                          |NULL|NULL    |NULL     |0          |Serializable  |true         |{numFiles -> 3, numOutputRows -> 3, numOutputBytes -> 4498}|NULL        |Apache-Spark/3.5.5 Delta-Lake/3.0.0|\n",
      "|0      |2025-04-22 20:36:08.335|NULL  |NULL    |CREATE TABLE|{isManaged -> true, description -> NULL, partitionBy -> [], properties -> {}}|NULL|NULL    |NULL     |NULL       |Serializable  |true         |{}                                                         |NULL        |Apache-Spark/3.5.5 Delta-Lake/3.0.0|\n",
      "+-------+-----------------------+------+--------+------------+-----------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostra o histórico sem quebrar dados\n",
    "cliente.history().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4763be94-ace5-490a-b531-898af8dd52d6",
   "metadata": {},
   "source": [
    "# ALTERANDO TABELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95040b92-1555-4507-8df8-33c48f5554f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionando coluna\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    alter table default.clientes_delta add column cidade STRING\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "543d082c-38a8-4917-bcae-ba2eabfe4e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+---+------+--------------+------+\n",
      "| id|     nome_cliente| uf|status|limite_credito|cidade|\n",
      "+---+-----------------+---+------+--------------+------+\n",
      "|  3|Matheus Daminelli| SC|  true|     4000000.0|  NULL|\n",
      "|  1|   Jean Guichard²| RS| false|         1.0E7|  NULL|\n",
      "|  2|    Lucas da Rosa| SC|  true|     1000000.0|  NULL|\n",
      "+---+-----------------+---+------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * from default.clientes_delta\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d68d65-b5b3-4d13-88e6-3eb71341dc21",
   "metadata": {},
   "source": [
    "# UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bcdce20-f25e-4b13-a12c-b3967b969991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE default.clientes_delta\n",
    "    SET cidade = CASE\n",
    "        WHEN id = 1 THEN 'Torres'\n",
    "        WHEN id = 2 THEN 'Tubarão'\n",
    "        WHEN id = 3 THEN 'Criciúma'\n",
    "        ELSE cidade\n",
    "    END\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac97c1be-ed2a-445b-998c-d6f1f632335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+---+------+--------------+--------+\n",
      "| id|     nome_cliente| uf|status|limite_credito|  cidade|\n",
      "+---+-----------------+---+------+--------------+--------+\n",
      "|  3|Matheus Daminelli| SC|  true|     4000000.0|Criciúma|\n",
      "|  2|    Lucas da Rosa| SC|  true|     1000000.0| Tubarão|\n",
      "|  1|   Jean Guichard²| RS| false|         1.0E7|  Torres|\n",
      "+---+-----------------+---+------+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * from default.clientes_delta\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09043b98-965b-4d3c-b55b-42464c3ec39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novo dado\n",
    "new_data_cliente = [\n",
    "    (\"4\",\"Teste da Silva\",\"SP\",\"false\", 100.00, 'São Paulo'),\n",
    "] # Novo lote da partição do data lake\n",
    "\n",
    "df_new_cliente = spark.createDataFrame(data=new_data_cliente, schema=schema_cliente) # Cria um dataframe com os novo dados\n",
    "\n",
    "df_new_cliente.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58390a-17ab-4eff-bd36-565ef3f1e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    cliente.alias(\"dados_atuais\")\n",
    "    .merge(\n",
    "        df_new_cliente.alias(\"novos_dados\"),\n",
    "        \"dados_atuais.id = novos_dados.id\" # Relacionamento de chaves\n",
    "    )\n",
    "    .whenMatchedUpdateAll()\n",
    "    .whenNotMatchedInsertAll() # All se refere a todos os dados, caso queira especificar, é possível remover o all colocar apenas o desejado.\n",
    "    .execute() # executa\n",
    ")\n",
    "cliente.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc947fb3-51d9-4f83-824b-19b2ca8ebf05",
   "metadata": {},
   "source": [
    "### Verifica se é uma delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fbc7c7f-1364-4f88-8de1-b029f797fb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeltaTable.isDeltaTable(spark, \"spark-warehouse/clientes_delta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d25b7-a835-4bd3-aa2d-a4d33cdef324",
   "metadata": {},
   "source": [
    "# DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10339e9a-cc29-46fe-bd88-9b1dd7ab87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "        DELETE FROM default.clientes_delta\n",
    "        WHERE uf = 'RS' AND status = false\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95724fe9-0fbc-4607-b2f6-f3e4da491b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * from default.clientes_delta\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b208b-a8e1-4d00-b88b-a67de64a9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cliente.delete(\"limite_credito < 200.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402886bd-686e-476b-9160-a684cf353cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cliente.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48894656-54ce-4b54-bf46-6eaf7b8e92ba",
   "metadata": {},
   "source": [
    "# Exibição em Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85bc0d-c84f-4a66-a7b4-ad4e3dfc2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e08a6-93a1-4426-b7cc-bee39af32416",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('describe HISTORY cliente_delta').show(truncate=False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
